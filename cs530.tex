\documentclass[article]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{outlines}
\usepackage{filecontents}
\usepackage{amsmath}
\usepackage[]{algorithm2e}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{graphicx}
\graphicspath{{./images/}}


\begin{document}
\title{Simulating and Surveying Fault Avoidance Efficacy of Majority Voting Systems with N-Version Software Systems}
\author{Allison Chilton\\\texttt{ allison.chilton@colostate.edu}\\CS530 - Yashwant Malaiya}
\date{April 2021}

\maketitle


\begin{abstract}
This survey compares majority voting schemes for alike and disalike voter subsystems in an N-Version System. It explores how disalike voter schemes are likely to correct particular kinds of faults, perhaps more successfully than alike subsystems. It simulates the performance of disalike voting schemes and compares the results to a simulated alike voting scheme. It also explores how this architecture may make detecting certain kinds of faults more easy at the cost of making others more difficult.
\hfill\\\\
\textbf{Keywords: N-Version, Fault-Tolerant Software, Survey, Simulation}
\end{abstract}



\section{Introduction}
\par
Often majority voter schemes (such as TMR) are proposed to address faults within a system where the system design is assumed to be correct but environmental and mechanical faults are inevitable. Because of this, very often the voting mechanisms use identical subsystems to perform as voting agents. Further, in many formulations, it is considered a requirement that such agents be identical for the correctness of the algorithm. This does not protect against system design flaws and human error when defining requirements. This will explore using intentionally disalike subsystems with discrete outputs and voting cycles, also known as N-Version fault-tolerant software systems, to measure performance of its fault avoidance success. 
%Additionally, I would like to explore how following this paradigm might be incompatible with other approaches, such as the State Machine Replication of Byzantine fault avoidance. 
\par
The topic of N-Version fault-tolerant software schemes are well known in the literature. In brief, the fundamental idea is that a system that is designed independently by different teams, where each subsystem votes to form a consensus for a discretized time step, will show more fault-tolerance to design defects because teams will likely average out their misunderstandings of ambiguous or imperfect design requirements. There is disagreement about whether this is indeed effective, perhaps because people are likely to misinterpret something in the same wrong way. 
\par
The primary contribution of this paper is to review the state of the literature, contrast the arguments, and submit the author's own software simulation for various scenarios. The author will cover the initial hypothesis that lead to this research, and analyze the results to see if that hypothesis was confirmed.
\par
The paper is laid out to introduce the reader to the concept, and to then review the literature for the field's current understanding. Following that, a methodology will be describes to provide a basic rationale for the author's hypothesis, and the simulation that was performed to confirm (or deny) that hypothesis. Finally, the paper will end with a conclusion and related works section.


\section{Literature Review}

\subsection{Foundational Works}


\subsection{N-version programming: A fault-tolerance approach to reliability of software operation}
% https://www.inf.pucrs.br/zorzo/cs/n-versionprogramming.pdf
One of the first papers academically defining and quantifying N-Version programming.
\\ 
Makes argument that multiple element redundancy in hardware does not translate well to software, because usually software faults are from design or implementation flaws rather than physical properties. That is, with the same inputs, multiple copies of software provide no additional utility because they will produce the same wrong output. 
\\ 
Not suitable to say "just make it correct" because even with large amounts of effort it has been demonstrated to be exceedingly difficult to build perfect software without issue. 
\\
Authors argue that essentially, multiple different versions of the software working together to check in at regular intervals to majority vote decide some datum is the software equivalent of multiple hardware copies.


Authors methods and conclusions are sound. I think it is somewhat of a stretch to assert that N-Version software is the same as multiple redundant hardware. PCBs or other hardware could have the same flaws and produce the same wrong outputs in some electrical design, or some other equivalent physical similarity causing an incorrect output. Having multiple copies of those would yield the same problem as software. Therefore it is best to just quantify the kinds of errors as separate domains that both need to be addressed. First there are the kind of faults brought on by incorrect design or some implementation issue or mistake of the engineer, and then there are environmental faults which cause correct systems to operate incorrectly. What the authors should have instead stated, and perhaps empirically measured, is that hardware system faults are largely dominated by the environmental faults, whereas software systems are largely dominated by engineering faults. One could indeed build an N-Version voting system for electrical signals to prevent design faults, or one could run multiple copies of the same software on different devices which are susceptible to environmental faults (such as radiation upsets in spaceflight).
\cite{chen1978n}
\subsubsection{The methodology of n-version programming}
% https://www.researchgate.net/profile/Algirdas-Avizienis-2/publication/200031514_The_Methodology_of_N-Version_Programming/links/00b49539a3cd7be0af000000/The-Methodology-of-N-Version-Programming.pdf
Expanded the work done by UCLA team. 
\\ 
Interesting observation: detailing if an application has suitable "potential for diversity" in the specification. Over dictation of design requirements may yield worse results and is better suited for extensive single version verification and validation to formally prove correctness. % Avi88a Che90 Lyu92b

\cite{avizienis1995methodology}
\subsection{N-Version Programming for the Detection of Zero-day Exploits}
\cite{zerodayexp}
\subsection{An experimental evaluation of the assumption of independence in multiversion programming}
\cite{knightetal}
\subsubsection{Follow Up:}
\cite{kfollowup}



\subsection{Current Literature}
\subsubsection{New Wine in an Old Bottle: N-Version Programming for Machine Learning Components}
\cite{newwine}
\hfill\\
\par
\textbf{Summary:} 
\par
\textbf{Discussion:}

\subsubsection{N-version programming approach with implicit safety guarantee for complex dynamic system stabilization applications}
\cite{nadiretal}
\hfill\\
\par
\textbf{Summary:} 
\par
\textbf{Discussion:}

\subsubsection{Model Fusion: Weighted N-Version Programming for Resilient Autonomous Vehicle Steering Control}
\cite{wuetal}
\hfill\\
\par
\textbf{Summary:} 
\par
\textbf{Discussion:}

\subsubsection{N-version machine learning models for safety critical systems}
\cite{machida2019n}
\hfill\\
\par
\textbf{Summary:} 
\par
\textbf{Discussion:}

\subsubsection{Application of majority voting and consensus voting algorithms in N-version software}
\cite{Tsarev_2018}
\hfill\\
\par
\textbf{Summary:} 
\par
\textbf{Discussion:}

%\section{Literature Matrix}
\section{Approach}
To gain some insight to the performance of these schemes, I wrote some random monte carlo simulations that have voter subsystems that artificially model being designed and built using similar but not identical interpretations of requirements. They have a randomly determined threshold to detect a particular domain of artificially inserted faults. There is also a parameter to test false positives. The idea is that in doing so, you are likely to average out the discrepancies in requirement interpretation and lead to more optimal performance. Additionally, I wrote simulations that use identical detections of particular fault domains, as a basis of comparison.  Additionally, I explored the effects of assigning weights to voter agents, in situations where a particular unit could be rigorously verified and tested, augmented by a higher quantity of lower quality backup devices. Finally, we'll analyze how this approach might be incompatible with other approaches, and the pro/cons of when it might be appropriate to use one approach or the other given your requirements. 

\begin{algorithm}
    \KwData{\newline
        \textbf{fset:} a set of faults and whether they are active
        \textbf{random\_subsystem:} a subsystem voter with a random probability of missing a fault or falsely detecting a fault when not present
        \textbf{random\_system:} a system with identical or non-identical subsystem voters
    }
    \KwResult{a collection of random trial results}
    results := \For{iter..trials }{
        votes := \ForEach{random\_subsystem in random\_system}{
            \ForEach{fault in fset}{
                \eIf{fault present}{hit\_prob := $P(\overline{FaultMissed} \cap FalsePositive)$ }
                {hit\_prob := $P(FalsePositive)$ }

                \eIf{uniform\_chance $<$ hit\_prob}{
                    collect vote := detected
                }
                {
                    collect vote := not-detected
                }
            }
        }
        collect result := majority\_vote(votes)

    }
    \Return{results}
    \caption{N-Modular Monte Carlo Simulation Approach}
\end{algorithm}

\section{Results}
In order to avoid sample bias, I needed to randomly generate several different situations. However, this causes the random distribution to cancel out its discrepant outliers, likely making differentiating the merit of either approach more difficult when testing the average performance. A better metric is to measure the variance and/or standard deviation of all performances in the distribution to determine the probability of being off nominal given a randomly “manufactured” device.
\par
There are static results in a table that describe a nominal setup, as well as a variant set of setups that vary a particular field to observe how the different types of configurations adjust their various measurements - correct percentage, standard deviation, p-values - based on the variation of that particular field. The variances change the parameter to be -+50\% the nominal setup.


\input{fig1.tex}
\input{plots.tex}

\textit{Insert more plots varying other things}

\subsection{Discussion}
\par You can see a trend in both the tables and plots. Our initial hypothesis was correct - in most cases the unweighted disalike (aka the N-Modular) system performed better than the alike. How you interpret performance here is subjective - if you look at the percent correct they are well within the margin of error and with more trials its likely the averaged out result would be even less pronounced. However, the variance / standard deviation of the population is the particular trend that we should observe. The standard deviation is almost always consistently lower by a not statistically insignifcant amount (as shown by the p-values in the table and plots). This confirms our initial conjecture: given any random system configuration, you are statistically more likely to be closer to the mean if you have an N-Modular system.

\section{Other works}
\section{Conclusion and Future Work}

\begin{filecontents}[overwrite]{cs530bib.bib}
  @inproceedings{chen1978n,
  title={N-version programming: A fault-tolerance approach to reliability of software operation},
  author={Chen, Liming and Avizienis, Algirdas},
  booktitle={Proc. 8th IEEE Int. Symp. on Fault-Tolerant Computing (FTCS-8)},
  volume={1},
  pages={3--9},
  year={1978}
}

@article{avizienis1995methodology,
  title={The methodology of n-version programming},
  author={Avizienis, Algirdas},
  journal={Software fault tolerance},
  volume={3},
  pages={23--46},
  year={1995},
  publisher={John Wiley \& Sons, New York}
}

@article{zerodayexp,
author = {Nagy, Lajos and Ford, Richard and Allen, William},
year = {2006},
month = {01},
pages = {},
title = {N-Version Programming for the Detection of Zero-day Exploits}
}

@ARTICLE{knightetal,
  author={J. C. {Knight} and N. G. {Leveson}},  
journal={IEEE Transactions on Software Engineering},
   title={An experimental evaluation of the assumption of independence in multiversion programming},
      year={1986},  volume={SE-12},  number={1},  pages={96-109},  doi={10.1109/TSE.1986.6312924}
      }
 
@article{kfollowup,
author = {Knight, John C. and Leveson, Nancy G.},
title = {A Reply to the Criticisms of the Knight and Leveson Experiment},
year = {1990},
issue_date = {Jan 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/382294.382710},
doi = {10.1145/382294.382710},
journal = {SIGSOFT Softw. Eng. Notes},
pages = {24–35},
}

@INPROCEEDINGS{newwine,  author={A. {Gujarati} and S. {Gopalakrishnan} and K. {Pattabiraman}},  booktitle={2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},   title={New Wine in an Old Bottle: N-Version Programming for Machine Learning Components},   year={2020},  volume={},  number={},  pages={283-286},  doi={10.1109/ISSREW51248.2020.00086}}

@article{nadiretal,
author = {Nadir Subasi and Ufuk Guner and Ilker Ustoglu},
title ={N-version programming approach with implicit safety guarantee for complex dynamic system stabilization applications},
journal = {Measurement and Control},
volume = {0},
number = {0},
pages = {0020294019887473},
year = {0},
doi = {10.1177/0020294019887473},

URL = { 
        https://doi.org/10.1177/0020294019887473
    
},
eprint = { 
        https://doi.org/10.1177/0020294019887473
    
}
}

@INPROCEEDINGS{wuetal,  author={A. {Wu} and A. H. M. {Rubaiyat} and C. {Anton} and H. {Alemzadeh}},  booktitle={2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},   title={Model Fusion: Weighted N-Version Programming for Resilient Autonomous Vehicle Steering Control},   year={2018},  volume={},  number={},  pages={144-145},  doi={10.1109/ISSREW.2018.00-11}}

@inproceedings{machida2019n,
  title={N-version machine learning models for safety critical systems},
  author={Machida, Fumio},
  booktitle={2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)},
  pages={48--51},
  year={2019},
  organization={IEEE}
}

@article{Tsarev_2018,
	doi = {10.1088/1742-6596/1015/4/042059},
	url = {https://doi.org/10.1088/1742-6596/1015/4/042059},
	year = 2018,
	month = {may},
	publisher = {{IOP} Publishing},
	volume = {1015},
	pages = {042059},
	author = {R Yu Tsarev and M S Durmu{\c{s}} and I Üstoglu and V A Morozov},
	title = {Application of majority voting and consensus voting algorithms in N-version software},
	journal = {Journal of Physics: Conference Series}
}

\end{filecontents}

\appendix
\section{Source Code}
Full source for simulation available at \url{ https://github.com/allisonChilton/n_modular_voting_sim/blob/master/tp_sim.py}

\bibliographystyle{unsrt}
\bibliography{cs530bib}

\end{document}


